Neural Network

activation functions: step, sigmoid, taan; ReLU, Leaky ReLU, ELU
suggestions for choosing activation functions: 
starting with a ReLU to obtain a baseline accuracy.

1. perceptron algorithm

1.1 AND、OR、XOR datasets
1.2 Perceptron Architecture
1.3 Perceptron Training Procedure and the Delta Rule
1.4 Perceptron Training Termination
